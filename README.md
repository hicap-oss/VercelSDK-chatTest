# Vercel AI SDK v5 Reference Implementation

A production-ready chat application demonstrating **best practices** for Vercel AI SDK v5 (`@ai-sdk/react` v2.x and `ai` v5.x) with Next.js 14+.

## üéØ Purpose

This app serves as a **reference implementation** showing the correct way to use Vercel AI SDK v5, which has a different API than older tutorials demonstrate. It showcases:

- ‚úÖ Proper `useChat` hook usage from `@ai-sdk/react`
- ‚úÖ Manual input state management (SDK v5 pattern)
- ‚úÖ Status-based loading states
- ‚úÖ Type-safe API routes with streaming
- ‚úÖ Dynamic model switching
- ‚úÖ Custom endpoint configuration
- ‚úÖ Raw stream debugging capabilities

## üìö Documentation

This project includes comprehensive documentation to help you understand and use Vercel AI SDK v5:

### üìñ [Complete Best Practices Guide](./VERCEL_SDK_V5_BEST_PRACTICES.md)
The definitive guide covering:
- SDK v5 architecture and concepts
- Detailed code walkthroughs with explanations
- Common pitfalls and how to avoid them
- Advanced features and patterns
- Security and performance best practices
- Testing recommendations and deployment checklist

### ‚ö° [Quick Reference Cheat Sheet](./SDK_V5_QUICK_REFERENCE.md)
A concise one-page reference with:
- Essential API patterns
- Common code snippets
- Status values and message structures
- Security and performance tips
- Troubleshooting quick fixes

### üîÑ [Migration Guide](./MIGRATION_GUIDE.md)
Step-by-step guide for upgrading from SDK v3/v4:
- Package and import changes
- Component migration examples
- API route updates
- Comparison tables
- Common migration issues and solutions

**üëâ Start with the [Best Practices Guide](./VERCEL_SDK_V5_BEST_PRACTICES.md) for a deep dive, or the [Quick Reference](./SDK_V5_QUICK_REFERENCE.md) for fast lookups.**

## üöÄ Quick Start

### Prerequisites

- Node.js 18+ 
- npm or pnpm
- API key for your AI provider

### Setup

1. **Clone and install dependencies:**

```bash
npm install
```

2. **Configure environment variables:**

Create `.env.local`:

```bash
cp .env.local.example .env.local
```

Add your API key:

```env
PROVIDER_API_KEY=your_api_key_here
```

3. **Run the development server:**

```bash
npm run dev
```

4. **Open the app:**

Navigate to [http://localhost:3000](http://localhost:3000)

## üèóÔ∏è Architecture

### Tech Stack

- **Frontend:** Next.js 14+ (App Router), React 18+, TypeScript
- **UI:** Tailwind CSS, shadcn/ui components
- **AI SDK:** @ai-sdk/react v2.x, ai v5.x
- **Runtime:** Edge Runtime for API routes

### File Structure

```
SDK Test/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ route.ts          # Streaming API endpoint
‚îÇ   ‚îú‚îÄ‚îÄ settings/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx              # Settings configuration
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                  # Main chat interface (client)
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx                # Root layout
‚îÇ   ‚îî‚îÄ‚îÄ globals.css               # Global styles
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ ui/                       # shadcn/ui components
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îî‚îÄ‚îÄ utils.ts                  # Utility functions
‚îú‚îÄ‚îÄ VERCEL_SDK_V5_BEST_PRACTICES.md  # üìñ Best practices guide
‚îî‚îÄ‚îÄ package.json
```

## ‚ú® Features

### Supported Models

- **Gemini 2.5 Pro** - Google's latest flagship model
- **Gemini 2.5 Flash** - Fast, efficient responses
- **Claude Sonnet 4** - Anthropic's balanced model
- **Claude Sonnet 4.5** - Enhanced capabilities

### Core Features

- üîÑ **Real-time Streaming** - Live AI responses as they're generated
- üé® **Modern UI** - Beautiful, responsive chat interface
- üß† **Thinking Display** - Shows AI reasoning process separately
- üîç **Raw Stream Debugging** - View raw API responses for troubleshooting
- ‚öôÔ∏è **Custom Endpoints** - Configure different API providers
- üì± **Responsive Design** - Works on desktop and mobile
- ‚ö° **Edge Runtime** - Fast response times with edge deployment
- üéØ **Type Safety** - Full TypeScript support

## üîë Key Differences from Other Tutorials

### ‚ö†Ô∏è Important: SDK v5 Has a Different API

Many tutorials show this pattern (‚ùå **outdated**):

```typescript
// ‚ùå This is from older SDK versions
const { messages, input, handleInputChange, handleSubmit, isLoading } = useChat();
```

**SDK v5 actually works like this** (‚úÖ **correct**):

```typescript
// ‚úÖ SDK v5 from @ai-sdk/react
const { messages, sendMessage, status, error } = useChat();

// You manage input yourself
const [input, setInput] = useState('');

// You derive loading state
const isLoading = status === 'submitted' || status === 'streaming';

// You create submit handler
const handleSubmit = async (e) => {
  e.preventDefault();
  setInput('');
  await sendMessage({ text: input }, { body: { model } });
};
```

### Why the Change?

SDK v5 adopts a **modular approach**:
- **Separation of concerns** - UI state vs. chat state
- **More flexible** - Works with any form library
- **Better TypeScript** - Improved type safety
- **Composable** - Easier to customize

## üìñ Usage Examples

### Basic Message Sending

```typescript
import { useChat } from '@ai-sdk/react';
import { useState } from 'react';

export default function Chat() {
  const [input, setInput] = useState('');
  const { messages, sendMessage, status } = useChat();
  
  const handleSubmit = async (e) => {
    e.preventDefault();
    if (!input.trim()) return;
    
    setInput('');
    await sendMessage({ text: input });
  };

  return (
    <div>
      {messages.map(m => (
        <div key={m.id}>{m.role}: {m.content}</div>
      ))}
      
      <form onSubmit={handleSubmit}>
        <input 
          value={input} 
          onChange={e => setInput(e.target.value)}
        />
        <button disabled={status === 'streaming'}>
          Send
        </button>
      </form>
    </div>
  );
}
```

### With Custom Parameters

```typescript
await sendMessage(
  { text: input },
  { 
    body: { 
      model: 'gemini-2.5-pro',
      temperature: 0.7,
      maxTokens: 1000
    } 
  }
);
```

### API Route Setup

```typescript
import { streamText } from 'ai';
import { createOpenAICompatible } from '@ai-sdk/openai-compatible';

export async function POST(req) {
  const { messages, model } = await req.json();
  
  const provider = createOpenAICompatible({
    baseURL: 'https://api.hicap.ai/v2/openai',
    headers: { 'api-key': process.env.PROVIDER_API_KEY },
  });

  const result = streamText({
    model: provider(model),
    messages,
  });

  return result.toUIMessageStreamResponse();
}
```

## üîß Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `PROVIDER_API_KEY` | Your AI provider API key | Yes |

### Default Settings

- **Default Model:** Gemini 2.5 Pro
- **Default Endpoint:** `https://api.hicap.ai/v2/openai/dev`
- **Throttle Rate:** 50ms (updates at most every 50ms during streaming)

### Customizing Endpoints

You can configure custom API endpoints in the Settings page (accessible via the settings icon in the header). The endpoint URL is saved to localStorage and persists across sessions.

## üß™ Testing

```bash
# Run linter
npm run lint

# Type check
npx tsc --noEmit

# Build for production
npm run build
```

## üö¢ Deployment

### Deploy to Vercel (Recommended)

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=YOUR_REPO_URL)

1. Push to GitHub
2. Import to Vercel
3. Add `PROVIDER_API_KEY` environment variable
4. Deploy!

### Other Platforms

This is a standard Next.js 14 app and can be deployed to any platform that supports Next.js:
- Netlify
- Cloudflare Pages
- AWS Amplify
- Self-hosted with Docker

## üêõ Troubleshooting

### Messages not appearing

‚úÖ Check that your API route returns `toUIMessageStreamResponse()`, not `toDataStreamResponse()`

### TypeScript errors on useChat

‚úÖ Make sure you're importing from `@ai-sdk/react`, not `ai`

### Input not working

‚úÖ Remember to manage input state manually in SDK v5

### See the [Best Practices Guide](./VERCEL_SDK_V5_BEST_PRACTICES.md) for more troubleshooting tips.

## üì¶ Dependencies

### Core
- `@ai-sdk/react` ^2.0.57 - React hooks for AI SDK
- `ai` ^5.0.57 - Core AI SDK functionality  
- `@ai-sdk/openai-compatible` - OpenAI-compatible provider
- `next` - Next.js framework
- `react` & `react-dom` - React library

### UI
- `tailwindcss` - Utility-first CSS
- `shadcn/ui` components - High-quality React components
- `lucide-react` - Icon library

## üìù License

This is a reference implementation for educational purposes. Feel free to use it as a template for your own projects.

## ü§ù Contributing

Found an issue or have a suggestion? This is a reference implementation, but feedback is welcome!

## üîó Resources

### Documentation (In This Repo)
- üìñ [**Best Practices Guide**](./VERCEL_SDK_V5_BEST_PRACTICES.md) - Complete SDK v5 reference
- ‚ö° [**Quick Reference**](./SDK_V5_QUICK_REFERENCE.md) - One-page cheat sheet
- üîÑ [**Migration Guide**](./MIGRATION_GUIDE.md) - Upgrade from v3/v4 to v5

### Official Resources
- [Vercel AI SDK Documentation](https://sdk.vercel.ai/)
- [Official SDK v5 Migration Guide](https://sdk.vercel.ai/docs/ai-sdk-ui/migration-guide)
- [Next.js Documentation](https://nextjs.org/docs)
- [GitHub: Vercel AI](https://github.com/vercel/ai)

### Example Code
- [Main Chat Component](./app/page.tsx) - Client-side implementation
- [Chat API Route](./app/api/chat/route.ts) - Server-side streaming

## üìß Questions?

1. **Quick answers:** Check the [Quick Reference](./SDK_V5_QUICK_REFERENCE.md)
2. **Detailed explanations:** Read the [Best Practices Guide](./VERCEL_SDK_V5_BEST_PRACTICES.md)
3. **Migrating from old SDK:** Follow the [Migration Guide](./MIGRATION_GUIDE.md)
4. **Still stuck?** Open an issue or check [Vercel Community](https://vercel.com/community)

---

**Built with ‚ù§Ô∏è to demonstrate Vercel AI SDK v5 best practices**
